#!/usr/bin/env python3
"""
Script optimizado para generar 10 millones de usuarios de forma rÃ¡pida
VersiÃ³n optimizada con multiprocesamiento y mejores tÃ©cnicas de inserciÃ³n

Autor: Sistema EU-UTVT
Fecha: Octubre 2025
"""

import asyncio
import time
import random
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
from datetime import datetime, timedelta
from typing import List, Dict, Tuple
import hashlib
from motor.motor_asyncio import AsyncIOMotorClient
from faker import Faker
import bcrypt
import sys
import os
import json

# ConfiguraciÃ³n optimizada
MONGO_URI = "mongodb://localhost:27017"
DATABASE_NAME = "eu_utvt_db"
COLLECTION_NAME = "users"

# ConfiguraciÃ³n de rendimiento
BATCH_SIZE = 5000      # Lotes mÃ¡s grandes para mejor rendimiento
TOTAL_USERS = 10_000_000
PROGRESS_INTERVAL = 100_000
CPU_CORES = mp.cpu_count()
MAX_WORKERS = min(CPU_CORES, 8)  # MÃ¡ximo 8 workers

print(f"ðŸ–¥ï¸ CPU cores detectados: {CPU_CORES}")
print(f"ðŸ‘· Workers a usar: {MAX_WORKERS}")

class OptimizedUserGenerator:
    def __init__(self):
        self.client = None
        self.db = None
        self.collection = None
        self.start_time = None
        self.users_created = 0
        
        # Pre-computar datos para acelerar generaciÃ³n
        self.departments = [
            "RectorÃ­a", "DirecciÃ³n AcadÃ©mica", "DirecciÃ³n Administrativa",
            "Finanzas", "Recursos Humanos", "Sistemas y TI", "Mantenimiento",
            "Biblioteca", "Servicios Escolares", "VinculaciÃ³n", "InvestigaciÃ³n",
            "Desarrollo AcadÃ©mico", "PlaneaciÃ³n", "JurÃ­dico", "ComunicaciÃ³n",
            "Calidad", "Seguridad", "Compras", "AlmacÃ©n", "Transporte"
        ]
        
        self.roles_distribution = [
            ("solicitante", 7000),  # 70%
            ("aprobador", 2000),    # 20%
            ("pagador", 800),       # 8%
            ("admin", 200)          # 2%
        ]
        
        self.email_domains = [
            "utvt.edu.mx", "gmail.com", "hotmail.com", "outlook.com",
            "yahoo.com", "live.com", "icloud.com"
        ]
        
        # Pre-generar algunos datos comunes
        self.common_passwords = [
            bcrypt.hashpw("password123".encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
            for _ in range(10)  # 10 passwords pre-hasheados
        ]
        
    async def connect_db(self):
        """Conectar a MongoDB con configuraciÃ³n optimizada"""
        print("ðŸ”Œ Conectando a MongoDB con configuraciÃ³n optimizada...")
        
        try:
            # ConfiguraciÃ³n optimizada para inserciones masivas
            self.client = AsyncIOMotorClient(
                MONGO_URI,
                maxPoolSize=50,  # Pool de conexiones mÃ¡s grande
                serverSelectionTimeoutMS=5000,
                socketTimeoutMS=30000,
                connectTimeoutMS=5000,
                retryWrites=True
            )
            
            self.db = self.client[DATABASE_NAME]
            self.collection = self.db[COLLECTION_NAME]
            
            # Verificar conexiÃ³n
            await self.client.admin.command('ping')
            print("âœ… ConexiÃ³n optimizada establecida")
            
            # Configurar para inserciones masivas
            await self.optimize_database()
            
        except Exception as e:
            print(f"âŒ Error conectando: {e}")
            sys.exit(1)
    
    async def optimize_database(self):
        """Optimizar configuraciÃ³n de base de datos para inserciones masivas"""
        print("âš¡ Optimizando base de datos para inserciones masivas...")
        
        try:
            # Desactivar validaciÃ³n temporal para mayor velocidad
            await self.db.command({
                "collMod": COLLECTION_NAME,
                "validator": {},
                "validationLevel": "off"
            })
            
            # Solo crear Ã­ndice esencial durante inserciÃ³n
            await self.collection.drop_indexes()
            
            print("âœ… Base de datos optimizada")
            
        except Exception as e:
            print(f"âš ï¸ Warning optimizando BD: {e}")
    
    async def create_final_indexes(self):
        """Crear Ã­ndices al final del proceso"""
        print("ðŸ“Š Creando Ã­ndices finales...")
        
        try:
            # Crear Ã­ndices en paralelo usando createIndexes
            index_specs = [
                {"key": {"email": 1}, "unique": True, "name": "email_unique"},
                {"key": {"role": 1, "department": 1}, "name": "role_dept"},
                {"key": {"is_active": 1, "role": 1}, "name": "active_role"},
                {"key": {"created_at": 1}, "name": "created_at"},
                {"key": {"user_id": 1}, "unique": True, "name": "user_id_unique"}
            ]
            
            await self.collection.create_indexes([
                {"key": spec["key"], **{k: v for k, v in spec.items() if k != "key"}}
                for spec in index_specs
            ])
            
            print("âœ… Ãndices creados")
            
        except Exception as e:
            print(f"âš ï¸ Warning creando Ã­ndices: {e}")
    
    async def insert_batch_optimized(self, users_batch: List[Dict]) -> bool:
        """InserciÃ³n optimizada de lotes"""
        try:
            # Usar insert_many con ordered=False para mejor rendimiento
            result = await self.collection.insert_many(
                users_batch, 
                ordered=False,
                bypass_document_validation=True  # Saltar validaciÃ³n para velocidad
            )
            return len(result.inserted_ids) == len(users_batch)
            
        except Exception as e:
            # Intentar inserciÃ³n uno por uno si falla el lote
            success_count = 0
            for user in users_batch:
                try:
                    await self.collection.insert_one(user)
                    success_count += 1
                except:
                    continue
            
            return success_count > 0
    
    async def generate_users_parallel(self):
        """Generar usuarios usando multiprocesamiento"""
        print("ðŸš€ Iniciando generaciÃ³n paralela de usuarios...")
        print(f"ðŸ“Š Total: {TOTAL_USERS:,} | Lotes: {BATCH_SIZE:,} | Workers: {MAX_WORKERS}")
        print("-" * 70)
        
        self.start_time = time.time()
        
        # Calcular rangos para cada worker
        total_batches = (TOTAL_USERS + BATCH_SIZE - 1) // BATCH_SIZE
        batches_per_worker = total_batches // MAX_WORKERS
        
        # Crear tareas para workers
        tasks = []
        current_start = 1
        
        for worker_id in range(MAX_WORKERS):
            # Calcular rango para este worker
            start_batch = worker_id * batches_per_worker
            end_batch = min((worker_id + 1) * batches_per_worker, total_batches)
            
            if worker_id == MAX_WORKERS - 1:  # Ãšltimo worker toma el resto
                end_batch = total_batches
            
            start_user_id = start_batch * BATCH_SIZE + 1
            end_user_id = min(end_batch * BATCH_SIZE, TOTAL_USERS)
            
            if start_user_id <= TOTAL_USERS:
                task = self.process_user_range(worker_id, start_user_id, end_user_id)
                tasks.append(task)
        
        # Ejecutar todas las tareas en paralelo
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Procesar resultados
        total_created = 0
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"âŒ Worker {i} fallÃ³: {result}")
            else:
                total_created += result
                print(f"âœ… Worker {i} completado: {result:,} usuarios")
        
        self.users_created = total_created
        await self.print_final_stats()
    
    async def process_user_range(self, worker_id: int, start_id: int, end_id: int) -> int:
        """Procesar un rango de usuarios (ejecutado por un worker)"""
        created_count = 0
        current_id = start_id
        
        print(f"ðŸ‘· Worker {worker_id}: procesando IDs {start_id:,} - {end_id:,}")
        
        while current_id <= end_id:
            batch_end = min(current_id + BATCH_SIZE - 1, end_id)
            batch_size = batch_end - current_id + 1
            
            # Generar lote de usuarios
            users_batch = await self.generate_batch_data(current_id, batch_size)
            
            # Insertar en BD
            if await self.insert_batch_optimized(users_batch):
                created_count += batch_size
                
                # Progreso por worker
                if created_count % (PROGRESS_INTERVAL // MAX_WORKERS) == 0:
                    elapsed = time.time() - self.start_time
                    rate = created_count / elapsed if elapsed > 0 else 0
                    print(f"ðŸ“ˆ Worker {worker_id}: {created_count:,} usuarios | {rate:.0f}/seg")
            
            current_id = batch_end + 1
        
        return created_count
    
    async def generate_batch_data(self, start_id: int, batch_size: int) -> List[Dict]:
        """Generar datos de lote optimizado"""
        users = []
        
        # Usar loop executor para generaciÃ³n intensiva de datos
        loop = asyncio.get_event_loop()
        users = await loop.run_in_executor(
            None, 
            self.generate_users_sync, 
            start_id, 
            batch_size
        )
        
        return users
    
    def generate_users_sync(self, start_id: int, batch_size: int) -> List[Dict]:
        """GeneraciÃ³n sÃ­ncrona optimizada (para executor)"""
        fake = Faker(['es_MX'])  # Una instancia por worker
        users = []
        
        for i in range(batch_size):
            user_id = start_id + i
            
            # Datos optimizados
            first_name = fake.first_name()
            last_name = fake.last_name()
            
            # Email Ãºnico simple
            domain = random.choice(self.email_domains)
            email = f"user{user_id}@{domain}"
            
            # Password pre-hasheado
            password = random.choice(self.common_passwords)
            
            # Rol basado en distribuciÃ³n
            role = self.select_role_fast(user_id)
            
            # Fechas simples
            created_at = fake.date_time_between(start_date='-1y', end_date='now')
            
            user_data = {
                "user_id": user_id,
                "email": email,
                "password": password,
                "first_name": first_name,
                "last_name": last_name,
                "department": random.choice(self.departments),
                "role": role,
                "phone": f"+52 {random.randint(100,999)} {random.randint(100,999)} {random.randint(1000,9999)}",
                "is_active": True,  # Todos activos para simplificar
                "created_at": created_at,
                "last_login": None,
                "profile": {
                    "employee_id": f"EMP{user_id:08d}",
                    "position": fake.job()
                },
                "metadata": {
                    "generated_at": datetime.utcnow(),
                    "batch_id": user_id // BATCH_SIZE
                }
            }
            
            users.append(user_data)
        
        return users
    
    def select_role_fast(self, user_id: int) -> str:
        """SelecciÃ³n rÃ¡pida de rol basada en ID"""
        # DistribuciÃ³n determinÃ­stica basada en ID
        mod = user_id % 10000
        
        if mod < 7000:
            return "solicitante"
        elif mod < 9000:
            return "aprobador"
        elif mod < 9800:
            return "pagador"
        else:
            return "admin"
    
    async def print_final_stats(self):
        """EstadÃ­sticas finales optimizadas"""
        total_time = time.time() - self.start_time
        
        print("\n" + "="*70)
        print("ðŸ GENERACIÃ“N MASIVA COMPLETADA")
        print("="*70)
        print(f"âœ… Usuarios generados: {self.users_created:,}")
        print(f"â±ï¸ Tiempo total: {total_time/60:.2f} minutos")
        print(f"ðŸš€ Velocidad: {self.users_created/total_time:.0f} usuarios/segundo")
        print(f"ðŸ‘· Workers utilizados: {MAX_WORKERS}")
        
        # Verificar en BD
        total_in_db = await self.collection.count_documents({})
        print(f"ðŸ—ƒï¸ Verificado en BD: {total_in_db:,}")
        
        # Crear Ã­ndices finales
        await self.create_final_indexes()
        
        print("="*70)
    
    async def cleanup(self):
        """Cleanup optimizado"""
        if self.client:
            self.client.close()

async def quick_verify():
    """VerificaciÃ³n rÃ¡pida de datos"""
    client = AsyncIOMotorClient(MONGO_URI)
    db = client[DATABASE_NAME]
    collection = db[COLLECTION_NAME]
    
    try:
        total = await collection.count_documents({})
        print(f"ðŸ” Total en BD: {total:,}")
        
        # DistribuciÃ³n por roles
        for role in ["solicitante", "aprobador", "pagador", "admin"]:
            count = await collection.count_documents({"role": role})
            print(f"   {role}: {count:,}")
            
    except Exception as e:
        print(f"âŒ Error verificando: {e}")
    finally:
        client.close()

async def main():
    """FunciÃ³n principal optimizada"""
    print("âš¡ GENERADOR MASIVO OPTIMIZADO - 10M USUARIOS")
    print("="*70)
    
    generator = OptimizedUserGenerator()
    
    try:
        await generator.connect_db()
        
        print(f"\nâš ï¸ Se generarÃ¡n {TOTAL_USERS:,} usuarios usando {MAX_WORKERS} workers")
        print("âš¡ Proceso optimizado para mÃ¡xima velocidad")
        response = input("\nðŸš€ Â¿Iniciar generaciÃ³n masiva? (y/N): ")
        
        if response.lower() != 'y':
            print("âŒ Cancelado")
            return
        
        await generator.generate_users_parallel()
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ Interrumpido. Creados: {generator.users_created:,}")
    except Exception as e:
        print(f"âŒ Error: {e}")
    finally:
        await generator.cleanup()

if __name__ == "__main__":
    # Verificar dependencias
    missing_deps = []
    for dep in ['motor', 'faker', 'bcrypt']:
        try:
            __import__(dep)
        except ImportError:
            missing_deps.append(dep)
    
    if missing_deps:
        print(f"âŒ Instalar: pip install {' '.join(missing_deps)}")
        sys.exit(1)
    
    # Ejecutar
    asyncio.run(main())
    
    # VerificaciÃ³n opcional
    verify = input("\nðŸ” Â¿Verificar resultados? (y/N): ")
    if verify.lower() == 'y':
        asyncio.run(quick_verify())